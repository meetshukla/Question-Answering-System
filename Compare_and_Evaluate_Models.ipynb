{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8QOE-oEKjQru"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiXMZ8DCGTAd"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ceLmdhiLCc2"
      },
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer,BertTokenizerFast, BertForQuestionAnswering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0rG0NeAglQu",
        "outputId": "6bbeadfe-93af-45c1-aa23-fd865e95ae66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1AlroecLHQw"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "modelSquad = torch.load(\"/content/drive/MyDrive/QA/finalFineTunedModelSquadV2\",map_location=torch.device('cpu'))\n",
        "modelNewsQA = torch.load(\"/content/drive/MyDrive/QA/finalFineTunedModelNewsQA\",map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=tokenizer.encode_plus('what is my name', 'my name is meet', return_tensors='pt')\n",
        "outputs=modelSquad(**inputs)\n",
        "answer_start = torch.argmax(outputs[0]) # get the most likely beginning of answer with the argmax of the score\n",
        "answer_end = torch.argmax(outputs[1]) + 1\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVeYyTms1__5",
        "outputId": "b6438bef-802a-4389-ed6d-8d5817c07b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjh85hqyY-2A"
      },
      "source": [
        "## Functions to make predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyWMyNM2ZFNd"
      },
      "source": [
        "Here I used some useful functions from the evaluation script of SQuAD dataset 2.0 so as to evaluate my fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbLzCx8FLN4K"
      },
      "source": [
        "def predict(model,context,query):\n",
        "\n",
        "  inputs = tokenizer.encode_plus(query, context, return_tensors='pt')\n",
        "\n",
        "  outputs = model(**inputs)\n",
        "  answer_start = torch.argmax(outputs[0])  # get the most likely beginning of answer with the argmax of the score\n",
        "  answer_end = torch.argmax(outputs[1]) + 1 \n",
        "\n",
        "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][answer_start:answer_end]))\n",
        "\n",
        "  return answer\n",
        "\n",
        "def normalize_text(s):\n",
        "  \"\"\"Removing articles and punctuation, and standardizing whitespace are all typical text processing steps.\"\"\"\n",
        "  import string, re\n",
        "\n",
        "  def remove_articles(text):\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    return re.sub(regex, \" \", text)\n",
        "\n",
        "  def white_space_fix(text):\n",
        "    return \" \".join(text.split())\n",
        "\n",
        "  def remove_punc(text):\n",
        "    exclude = set(string.punctuation)\n",
        "    return \"\".join(ch for ch in text if ch not in exclude)\n",
        "\n",
        "  def lower(text):\n",
        "    return text.lower()\n",
        "\n",
        "  return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(normalize_text(prediction) == normalize_text(truth))\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "  pred_tokens = normalize_text(prediction).split()\n",
        "  truth_tokens = normalize_text(truth).split()\n",
        "  \n",
        "  # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n",
        "  if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n",
        "    return int(pred_tokens == truth_tokens)\n",
        "  \n",
        "  common_tokens = set(pred_tokens) & set(truth_tokens)\n",
        "  \n",
        "  # if there are no common tokens then f1 = 0\n",
        "  if len(common_tokens) == 0:\n",
        "    return 0\n",
        "  \n",
        "  prec = len(common_tokens) / len(pred_tokens)\n",
        "  rec = len(common_tokens) / len(truth_tokens)\n",
        "  \n",
        "  return 2 * (prec * rec) / (prec + rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtMtke3JbCSR"
      },
      "source": [
        "def give_an_answer(context,query,answer):\n",
        "\n",
        "  prediction_newsQA = predict(modelNewsQA,context,query)\n",
        "  prediction_Squad = predict(modelSquad,context,query)\n",
        "  if(prediction_newsQA==\"[CLS]\" or prediction_newsQA==\"\" or prediction_newsQA==\"[SEP]\"):\n",
        "    prediction_newsQA=\"No answer predicted!!\"\n",
        "  if(prediction_Squad==\"[CLS]\" or prediction_Squad==\"\" or prediction_Squad==\"[SEP]\"):\n",
        "    prediction_Squad=\"No answer predicted!!\"\n",
        "  em_score_newsqa = compute_exact_match(prediction_newsQA, answer)\n",
        "  f1_score_newsqa = compute_f1(prediction_newsQA, answer)\n",
        "  em_score_squad = compute_exact_match(prediction_Squad, answer)\n",
        "  f1_score_squad = compute_f1(prediction_Squad, answer)\n",
        "\n",
        "  print(f\"Question: {query}\")\n",
        "  print(f\"True Answer: {answer}\")\n",
        "  print(\"-----------------------\")\n",
        "  print(f\"Prediction SQUAD: {prediction_Squad}\")\n",
        "  print(f\"EM SQUAD: {em_score_squad}\")\n",
        "  print(f\"F1 SQUAD: {f1_score_squad}\")\n",
        "  print(\"-----------------------\")\n",
        "  print(f\"Prediction NewsQA: {prediction_newsQA}\")\n",
        "  print(f\"EM NEWSQA: {em_score_newsqa}\")\n",
        "  print(f\"F1 NEWSQA: {f1_score_newsqa}\")\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2tXL-jNbKkK"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg6XNgM9b15M"
      },
      "source": [
        "##### Our both models perform great on simple example below!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smJvu24DPWxR",
        "outputId": "2338b9cd-6aaf-4b65-fa3a-ed76aa5fc413"
      },
      "source": [
        "context = \"Hello! My name is Liam and I am 29 years old. I used to live in Oakville of Ontario, but now I moved to Burlington of Ontario. I enjoy exploring new places and trying new foods. I have a passion for photography and enjoy taking pictures of the beautiful landscapes around me.\"\n",
        "\n",
        "queries = [\"What is my name?\",\n",
        "           \"What is age of liam?\",\n",
        "           \"Where does Liam live currently?\",\n",
        "           \"What is liam's passion?\"\n",
        "          ]\n",
        "answers = [\"Liam\",\n",
        "           \"29 years\",\n",
        "           \"Burlington\",\n",
        "           \"photography\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is my name?\n",
            "True Answer: Liam\n",
            "-----------------------\n",
            "Prediction SQUAD: liam\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: liam\n",
            "EM NEWSQA: 1\n",
            "F1 NEWSQA: 1.0\n",
            "\n",
            "\n",
            "Question: What is age of liam?\n",
            "True Answer: 29 years\n",
            "-----------------------\n",
            "Prediction SQUAD: 29\n",
            "EM SQUAD: 0\n",
            "F1 SQUAD: 0.6666666666666666\n",
            "-----------------------\n",
            "Prediction NewsQA: 29 years old.\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0.8\n",
            "\n",
            "\n",
            "Question: Where does Liam live currently?\n",
            "True Answer: Burlington\n",
            "-----------------------\n",
            "Prediction SQUAD: burlington\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: No answer predicted!!\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0\n",
            "\n",
            "\n",
            "Question: What is liam's passion?\n",
            "True Answer: photography\n",
            "-----------------------\n",
            "Prediction SQUAD: photography\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: photography\n",
            "EM NEWSQA: 1\n",
            "F1 NEWSQA: 1.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QOE-oEKjQru"
      },
      "source": [
        "##### Here I took some content from Wikipedia pages to test my model. I observed that for questions that requires an answer with more than one entities, that in the context are seperated by comma, the model return only the first one (in the question of the members of the band). Moreover, when I asked about the kind of band they are, the model give me the answer of \"British rock\", while I didn't asked about the origin of the band. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SsSHQMqU2oy",
        "outputId": "50926f8b-99cd-4558-c2e1-d7b54c3b8a25"
      },
      "source": [
        "context = \"\"\" The Great Barrier Reef is the world's largest coral reef system, located in the Coral Sea, off the coast of Australia. It is composed of over 2,900 individual reefs and 900 islands, stretching for over 2,300 km. The Great Barrier Reef is home to thousands of species of marine life, including over 1,500 species of fish and over 600 species of hard and soft coral.\"\"\"\n",
        "\n",
        "queries = [\"Where is the Great Barrier Reef located? \",\n",
        "           \"How long is great barrier reef?\",\n",
        "           \"What type of marine life in reef?\"\n",
        "          ]\n",
        "answers = [\"Coral Sea, off the coast of Australia\",\n",
        "           \"2, 300 km\",\n",
        "           \"over 1, 500 species of fish and over 600 species of hard and soft coral\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Where is the Great Barrier Reef located? \n",
            "True Answer: Coral Sea, off the coast of Australia\n",
            "-----------------------\n",
            "Prediction SQUAD: coral sea\n",
            "EM SQUAD: 0\n",
            "F1 SQUAD: 0.5\n",
            "-----------------------\n",
            "Prediction NewsQA: off the coast of australia.\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0.8\n",
            "\n",
            "\n",
            "Question: How long is great barrier reef?\n",
            "True Answer: 2, 300 km\n",
            "-----------------------\n",
            "Prediction SQUAD: 2, 300 km\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: over 2, 300 km.\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0.8571428571428571\n",
            "\n",
            "\n",
            "Question: What type of marine life in reef?\n",
            "True Answer: over 1, 500 species of fish and over 600 species of hard and soft coral\n",
            "-----------------------\n",
            "Prediction SQUAD: over 1, 500 species of fish and over 600 species of hard and soft coral\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 0.7333333333333333\n",
            "-----------------------\n",
            "Prediction NewsQA: coral\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0.125\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssAaoM6jj1RQ",
        "outputId": "a6ced222-a9e5-4ba5-f544-4d0da89cc777"
      },
      "source": [
        "context = \"\"\" Mount Olympus is the highest mountain in Greece. It is part of the Olympus massif near \n",
        "              the Gulf of Thérmai of the Aegean Sea, located in the Olympus Range on the border between \n",
        "              Thessaly and Macedonia, between the regional units of Pieria and Larissa, about 80 km (50 mi) \n",
        "              southwest from Thessaloniki. Mount Olympus has 52 peaks and deep gorges. The highest peak, \n",
        "              Mytikas, meaning \"nose\", rises to 2917 metres (9,570 ft). It is one of the \n",
        "              highest peaks in Europe in terms of topographic prominence. \"\"\"\n",
        "\n",
        "queries = [\n",
        "           \"How many metres is Olympus?\",\n",
        "           \"Where Olympus is near?\",\n",
        "           \"How far away is Olympus from Thessaloniki?\"\n",
        "          ]\n",
        "answers = [\n",
        "           \"2917\",\n",
        "           \"Gulf of Thérmai of the Aegean Sea\",\n",
        "           \"80 km (50 mi)\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How many metres is Olympus?\n",
            "True Answer: 2917\n",
            "-----------------------\n",
            "Prediction SQUAD: 2917\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: No answer predicted!!\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0\n",
            "\n",
            "\n",
            "Question: Where Olympus is near?\n",
            "True Answer: Gulf of Thérmai of the Aegean Sea\n",
            "-----------------------\n",
            "Prediction SQUAD: gulf of thermai of the aegean sea\n",
            "EM SQUAD: 0\n",
            "F1 SQUAD: 0.6666666666666666\n",
            "-----------------------\n",
            "Prediction NewsQA: gulf of thermai of the aegean sea,\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0.6666666666666666\n",
            "\n",
            "\n",
            "Question: How far away is Olympus from Thessaloniki?\n",
            "True Answer: 80 km (50 mi)\n",
            "-----------------------\n",
            "Prediction SQUAD: 80 km\n",
            "EM SQUAD: 0\n",
            "F1 SQUAD: 0.6666666666666666\n",
            "-----------------------\n",
            "Prediction NewsQA: about 80 km ( 50 mi )\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0.888888888888889\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Here we give it a a little big paragraph and still it is able to answer most questions apart from 6th one where some hoping is required and"
      ],
      "metadata": {
        "id": "puKKp2mmyGEd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6c16XCHoRTX",
        "outputId": "f326c864-dd62-4147-a912-b9fdeeab44fd"
      },
      "source": [
        "context = \"\"\" The human brain is one of the most complex and fascinating organs in the human body. It weighs about 3 pounds and is respon\n",
        "            sible for everything we do, think, and feel. The brain is divided into several parts, each with a specific function. The cerebral cortex, which is the outer \n",
        "            layer of the brain, is responsible for consciousness, thought, and movement. The cerebellum, located at the base of the brain, controls movement and \n",
        "            balance. The brainstem, which connects the brain to the spinal cord, controls involuntary functions such as breathing and heart rate. The brain is composed of over \n",
        "            100 billion neurons, which communicate with each other through electrical and chemical signals. The neurons are connected by synapses, which are the gaps between them. \n",
        "            The synapses allow the neurons to transmit information quickly and efficiently. The brain is also responsible for creating and storing \n",
        "            memories, which are formed through the process of encoding, storage, and retrieval.\"\"\"\n",
        "\n",
        "queries = [\n",
        "           \"How much does the human brain weigh?\",\n",
        "           \"What is the function of the cerebellum?\",\n",
        "           \"What is the cerebral cortex responsible for?\",\n",
        "           \"What do synapses do?\",\n",
        "           \"How are memories formed? \",\n",
        "           \"where is the organ responsible for consciousness, thought, and movement located?\",\n",
        "           \"what do peacocks eat?\"\n",
        "          ]\n",
        "answers = [\n",
        "           \"about 3 pounds\",\n",
        "           \"controls movement and balance\",\n",
        "           \"consciousness, thought, and movement\",\n",
        "           \"allow the neurons to transmit information quickly and efficiently.\",\n",
        "           \"encoding, storage, and retrieval\",\n",
        "           \"outer layer of the brain\",\n",
        "           \"\"\n",
        "          ]\n",
        "\n",
        "for q,a in zip(queries,answers):\n",
        "  give_an_answer(context,q,a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: How much does the human brain weigh?\n",
            "True Answer: about 3 pounds\n",
            "-----------------------\n",
            "Prediction SQUAD: about 3 pounds\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: about 3 pounds\n",
            "EM NEWSQA: 1\n",
            "F1 NEWSQA: 1.0\n",
            "\n",
            "\n",
            "Question: What is the function of the cerebellum?\n",
            "True Answer: controls movement and balance\n",
            "-----------------------\n",
            "Prediction SQUAD: controls movement and balance\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: controls movement and balance.\n",
            "EM NEWSQA: 1\n",
            "F1 NEWSQA: 1.0\n",
            "\n",
            "\n",
            "Question: What is the cerebral cortex responsible for?\n",
            "True Answer: consciousness, thought, and movement\n",
            "-----------------------\n",
            "Prediction SQUAD: consciousness, thought, and movement\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: consciousness, thought, and movement.\n",
            "EM NEWSQA: 1\n",
            "F1 NEWSQA: 1.0\n",
            "\n",
            "\n",
            "Question: What do synapses do?\n",
            "True Answer: allow the neurons to transmit information quickly and efficiently.\n",
            "-----------------------\n",
            "Prediction SQUAD: allow the neurons to transmit information quickly and efficiently\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: allow the neurons to transmit information quickly and efficiently.\n",
            "EM NEWSQA: 1\n",
            "F1 NEWSQA: 1.0\n",
            "\n",
            "\n",
            "Question: How are memories formed? \n",
            "True Answer: encoding, storage, and retrieval\n",
            "-----------------------\n",
            "Prediction SQUAD: encoding, storage, and retrieval\n",
            "EM SQUAD: 1\n",
            "F1 SQUAD: 1.0\n",
            "-----------------------\n",
            "Prediction NewsQA: over 100 billion neurons,\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0\n",
            "\n",
            "\n",
            "Question: where is the organ responsible for consciousness, thought, and movement located?\n",
            "True Answer: outer layer of the brain\n",
            "-----------------------\n",
            "Prediction SQUAD: the cerebral cortex\n",
            "EM SQUAD: 0\n",
            "F1 SQUAD: 0\n",
            "-----------------------\n",
            "Prediction NewsQA: cerebral cortex,\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0\n",
            "\n",
            "\n",
            "Question: what do peacocks eat?\n",
            "True Answer: \n",
            "-----------------------\n",
            "Prediction SQUAD: No answer predicted!!\n",
            "EM SQUAD: 0\n",
            "F1 SQUAD: 0\n",
            "-----------------------\n",
            "Prediction NewsQA: No answer predicted!!\n",
            "EM NEWSQA: 0\n",
            "F1 NEWSQA: 0\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}